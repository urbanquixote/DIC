{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xl5LcRN67zSo"
   },
   "source": [
    "# <br>[ LG전자_DX_Intensive_Course  ] 딥러닝 기반 시계열 분석 3<br><br>: CNN 주요 모델 2 & CAM/Grad-CAM - CNN for Time Series Data<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# github에서 데이터 불러오기\n",
    "!git clone https://github.com/KU-DIC/LG_time_series_day10.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:23.496900Z",
     "iopub.status.busy": "2022-01-10T11:57:23.496247Z",
     "iopub.status.idle": "2022-01-10T11:57:24.890360Z",
     "shell.execute_reply": "2022-01-10T11:57:24.889665Z",
     "shell.execute_reply.started": "2022-01-10T11:57:23.496804Z"
    },
    "id": "y7fxgeFP7zSt"
   },
   "outputs": [],
   "source": [
    "# 모듈 불러오기\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39QvLK8T7zSv"
   },
   "source": [
    "# <br>0. Hyperparameter Setting\n",
    "- data_dir: 데이터가 존재하는 경로 (해당 실습에서는 train/test 시계열 데이터가 존재하는 경로를 의미함)\n",
    "- batch_size: 학습 및 검증에 사용할 배치의 크기\n",
    "- num_classes: 새로운 데이터의 class 개수\n",
    "- num_epochs: 학습할 epoch 횟수\n",
    "- window_size: input의 시간 길이 (time series data에서 도출한 subsequence의 길이)\n",
    "- random_seed: reproduction을 위해 고정할 seed의 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:24.892065Z",
     "iopub.status.busy": "2022-01-10T11:57:24.891837Z",
     "iopub.status.idle": "2022-01-10T11:57:24.945806Z",
     "shell.execute_reply": "2022-01-10T11:57:24.944894Z",
     "shell.execute_reply.started": "2022-01-10T11:57:24.892033Z"
    },
    "id": "H1wdGxpZ7zSv"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter setting\n",
    "data_dir = '/content/LG_time_series_day10/input/har-data'\n",
    "batch_size = 32\n",
    "num_classes = 6\n",
    "num_epochs = 50\n",
    "window_size = 50\n",
    "\n",
    "random_seed = 42\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Detect if we have a GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:24.948561Z",
     "iopub.status.busy": "2022-01-10T11:57:24.948040Z",
     "iopub.status.idle": "2022-01-10T11:57:24.956520Z",
     "shell.execute_reply": "2022-01-10T11:57:24.955691Z",
     "shell.execute_reply.started": "2022-01-10T11:57:24.948517Z"
    },
    "id": "mbayPNZ47zSw"
   },
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7mZXU_J7zSw"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5KlXOLD7zSw"
   },
   "source": [
    "# <br>__1. Data: Human Activity Recognition Data__\n",
    "- 데이터 description\n",
    "    - Human Activity Recognition (HAR) Data는 30명의 실험자들이 각자 스마트폰을 허리에 착용하고 6가지 활동 (Walking, Walking Upstairs, Walking Downstairs, Sitting, Standing, Laying)을 수행할 때 측정된 센서 데이터로 구성된 데이터셋이다. 해당 데이터셋은 총 561개의 변수로 이루어져 있으며, 전체 데이터 중 70%는 train 데이터이고 나머지 30%는 test 데이터이다. HAR Data를 활용한 시계열 분류 task는 다변량 시계열 데이터를 input으로 받아 이를 다음 6가지 활동 중 하나의 class로 분류하는 것을 목표로 한다: 0(Walking), 1(Walking Upstairs), 2(Walking Downstairs), 3(Sitting), 4(Standing), 5(Laying). <br><br>\n",
    "\n",
    "- 변수 설명\n",
    "    - 독립변수(X): 여러 실험자에 대하여 561개의 변수를 281 시점동안 수집한 시계열 데이터 -> shape: (#실험자, 561, 281)\n",
    "    - 종속변수(Y): 시계열 데이터의 label - 0(Walking) / 1(Walking Upstairs) / 2(Walking Downstairs) / 3(Sitting) / 4(Standing) / 5(Laying) <br><br>\n",
    "\n",
    "- 데이터 출처\n",
    "    - https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:24.959362Z",
     "iopub.status.busy": "2022-01-10T11:57:24.958982Z",
     "iopub.status.idle": "2022-01-10T11:57:24.971461Z",
     "shell.execute_reply": "2022-01-10T11:57:24.970553Z",
     "shell.execute_reply.started": "2022-01-10T11:57:24.959296Z"
    },
    "id": "XJwE1FKT7zSx"
   },
   "outputs": [],
   "source": [
    "def create_classification_dataset(window_size, data_dir, batch_size):\n",
    "    # data_dir에 있는 train/test 데이터 불러오기\n",
    "    x = pickle.load(open(os.path.join(data_dir, 'x_train.pkl'), 'rb'))\n",
    "    y = pickle.load(open(os.path.join(data_dir, 'state_train.pkl'), 'rb'))\n",
    "    x_test = pickle.load(open(os.path.join(data_dir, 'x_test.pkl'), 'rb'))\n",
    "    y_test = pickle.load(open(os.path.join(data_dir, 'state_test.pkl'), 'rb'))\n",
    "\n",
    "    # train data를 시간순으로 8:2의 비율로 train/validation set으로 분할\n",
    "    # train, validation, test data의 개수 설정\n",
    "    n_train = int(0.8 * len(x))\n",
    "    n_valid = len(x) - n_train\n",
    "    n_test = len(x_test)\n",
    "    # train/validation set의 개수에 맞게 데이터 분할\n",
    "    x_train, y_train = x[:n_train], y[:n_train]\n",
    "    x_valid, y_valid = x[n_train:], y[n_train:]\n",
    "\n",
    "    # train/validation/test 데이터를 window_size 시점 길이로 분할\n",
    "    datasets = []\n",
    "    for set in [(x_train, y_train, n_train), (x_valid, y_valid, n_valid), (x_test, y_test, n_test)]:\n",
    "        # 전체 시간 길이 설정\n",
    "        T = set[0].shape[-1]\n",
    "        # 전체 X 데이터를 window_size 크기의 time window로 분할\n",
    "        windows = np.split(set[0][:, :, :window_size * (T // window_size)], (T // window_size), -1)\n",
    "        windows = np.concatenate(windows, 0)\n",
    "        # 전체 y 데이터를 window_size 크기에 맞게 분할\n",
    "        labels = np.split(set[1][:, :window_size * (T // window_size)], (T // window_size), -1)\n",
    "        labels = np.round(np.mean(np.concatenate(labels, 0), -1))\n",
    "        # 분할된 time window 단위의 X, y 데이터를 tensor 형태로 축적\n",
    "        datasets.append(torch.utils.data.TensorDataset(torch.Tensor(windows), torch.Tensor(labels)))\n",
    "\n",
    "    # train/validation/test DataLoader 구축\n",
    "    trainset, validset, testset = datasets[0], datasets[1], datasets[2]\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(validset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:24.973087Z",
     "iopub.status.busy": "2022-01-10T11:57:24.972659Z",
     "iopub.status.idle": "2022-01-10T11:57:25.680227Z",
     "shell.execute_reply": "2022-01-10T11:57:25.679539Z",
     "shell.execute_reply.started": "2022-01-10T11:57:24.973052Z"
    },
    "id": "hW87lEgd7zSy"
   },
   "outputs": [],
   "source": [
    "# Dataloader 구축\n",
    "# data shape: (batch_size x input_size x seq_len)\n",
    "train_loader, valid_loader, test_loader = create_classification_dataset(window_size, data_dir, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4gBeZhJ7zSz"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ITBf8Px7zS0"
   },
   "source": [
    "# <br>__2. Model: 1D CNN__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLiuFRF87zS0"
   },
   "source": [
    "- 1-dimensional convolution layer 설명 - **torch.nn.Conv1d()**\n",
    "    - in_channels: input image의 채널 개수 (시계열 데이터에서는 변수 개수)\n",
    "    - out_channels: 1-dimensional convolution의 output의 채널 개수 (kernel 개수)\n",
    "    - kernel_size: 1-dimensional convolution의 kernel 크기 (한 kernel에서 고려할 시점의 길이)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:25.682701Z",
     "iopub.status.busy": "2022-01-10T11:57:25.682293Z",
     "iopub.status.idle": "2022-01-10T11:57:25.690326Z",
     "shell.execute_reply": "2022-01-10T11:57:25.689485Z",
     "shell.execute_reply.started": "2022-01-10T11:57:25.682664Z"
    },
    "id": "xgW3b8IY7zS1"
   },
   "outputs": [],
   "source": [
    "# 1-dimensional convolution layer로 구성된 CNN 모델\n",
    "# 2개의 1-dimensional convolution layer와 1개의 fully-connected layer로 구성되어 있음\n",
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_1D, self).__init__()\n",
    "        # 첫 번째 1-dimensional convolution layer 구축\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(561, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(2)\n",
    "        )\n",
    "        # 두 번째 1-dimensional convolution layer 구축\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(2)\n",
    "        )\n",
    "        # fully-connected layer 구축\n",
    "        self.fc = nn.Linear(64 * 11, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:25.693822Z",
     "iopub.status.busy": "2022-01-10T11:57:25.693348Z",
     "iopub.status.idle": "2022-01-10T11:57:28.539544Z",
     "shell.execute_reply": "2022-01-10T11:57:28.538836Z",
     "shell.execute_reply.started": "2022-01-10T11:57:25.693794Z"
    },
    "id": "V34bVgIb7zS1",
    "outputId": "2c1f1f08-5d99-4036-d837-37de85941200",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_1D(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv1d(561, 64, kernel_size=(3,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  )\n",
      "  (fc): Linear(in_features=704, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 1D CNN 구축\n",
    "model = CNN_1D(num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUI0_pXM7zS2"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqvEYQdH7zS2"
   },
   "source": [
    "# <br>__3. Training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:28.545690Z",
     "iopub.status.busy": "2022-01-10T11:57:28.543645Z",
     "iopub.status.idle": "2022-01-10T11:57:28.551978Z",
     "shell.execute_reply": "2022-01-10T11:57:28.550960Z",
     "shell.execute_reply.started": "2022-01-10T11:57:28.545649Z"
    },
    "id": "zUzmPAuf7zS2"
   },
   "outputs": [],
   "source": [
    "# SGD optimizer 구축하기\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:28.554235Z",
     "iopub.status.busy": "2022-01-10T11:57:28.553224Z",
     "iopub.status.idle": "2022-01-10T11:57:28.573777Z",
     "shell.execute_reply": "2022-01-10T11:57:28.573125Z",
     "shell.execute_reply.started": "2022-01-10T11:57:28.554194Z"
    },
    "id": "oRq7S_MN7zS2"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, num_epochs, optimizer):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # 각 epoch마다 순서대로 training과 validation을 진행\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # 모델을 training mode로 설정\n",
    "            else:\n",
    "                model.eval()   # 모델을 validation mode로 설정\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_total = 0\n",
    "\n",
    "            # training과 validation 단계에 맞는 dataloader에 대하여 학습/검증 진행\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "                # parameter gradients를 0으로 설정\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # training 단계에서만 gradient 업데이트 수행\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # input을 model에 넣어 output을 도출한 후, loss를 계산함\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # output 중 최댓값의 위치에 해당하는 class로 예측을 수행\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward (optimize): training 단계에서만 수행\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # batch별 loss를 축적함\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                running_total += labels.size(0)\n",
    "\n",
    "            # epoch의 loss 및 accuracy 도출\n",
    "            epoch_loss = running_loss / running_total\n",
    "            epoch_acc = running_corrects.double() / running_total\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # validation 단계에서 validation loss가 감소할 때마다 best model 가중치를 업데이트함\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    # 전체 학습 시간 계산\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # validation loss가 가장 낮았을 때의 best model 가중치를 불러와 best model을 구축함\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    # best model 가중치 저장\n",
    "    # torch.save(best_model_wts, '../output/best_model.pt')\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:28.576899Z",
     "iopub.status.busy": "2022-01-10T11:57:28.576320Z",
     "iopub.status.idle": "2022-01-10T11:57:28.585531Z",
     "shell.execute_reply": "2022-01-10T11:57:28.584719Z",
     "shell.execute_reply.started": "2022-01-10T11:57:28.576857Z"
    },
    "id": "S562UwT57zS3"
   },
   "outputs": [],
   "source": [
    "# trining 단계에서 사용할 Dataloader dictionary 생성\n",
    "dataloaders_dict = {\n",
    "    'train': train_loader,\n",
    "    'val': valid_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:28.587651Z",
     "iopub.status.busy": "2022-01-10T11:57:28.587260Z",
     "iopub.status.idle": "2022-01-10T11:57:28.594595Z",
     "shell.execute_reply": "2022-01-10T11:57:28.593208Z",
     "shell.execute_reply.started": "2022-01-10T11:57:28.587546Z"
    },
    "id": "EknMva187zS3"
   },
   "outputs": [],
   "source": [
    "# loss function 설정\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:28.596634Z",
     "iopub.status.busy": "2022-01-10T11:57:28.596213Z",
     "iopub.status.idle": "2022-01-10T11:57:34.972802Z",
     "shell.execute_reply": "2022-01-10T11:57:34.972106Z",
     "shell.execute_reply.started": "2022-01-10T11:57:28.596458Z"
    },
    "id": "mXYJZcGk7zS4",
    "outputId": "b4d3ad96-0835-43e7-e552-104779b589a5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "----------\n",
      "train Loss: 1.7940 Acc: 0.0500\n",
      "val Loss: 1.7857 Acc: 0.3200\n",
      "\n",
      "Epoch 2/50\n",
      "----------\n",
      "train Loss: 1.7794 Acc: 0.3250\n",
      "val Loss: 1.7625 Acc: 0.5600\n",
      "\n",
      "Epoch 3/50\n",
      "----------\n",
      "train Loss: 1.7528 Acc: 0.4125\n",
      "val Loss: 1.7210 Acc: 0.5200\n",
      "\n",
      "Epoch 4/50\n",
      "----------\n",
      "train Loss: 1.7123 Acc: 0.4125\n",
      "val Loss: 1.6561 Acc: 0.5200\n",
      "\n",
      "Epoch 5/50\n",
      "----------\n",
      "train Loss: 1.6480 Acc: 0.4125\n",
      "val Loss: 1.5660 Acc: 0.5200\n",
      "\n",
      "Epoch 6/50\n",
      "----------\n",
      "train Loss: 1.5564 Acc: 0.4125\n",
      "val Loss: 1.4425 Acc: 0.5200\n",
      "\n",
      "Epoch 7/50\n",
      "----------\n",
      "train Loss: 1.4384 Acc: 0.4125\n",
      "val Loss: 1.3250 Acc: 0.5200\n",
      "\n",
      "Epoch 8/50\n",
      "----------\n",
      "train Loss: 1.3473 Acc: 0.4125\n",
      "val Loss: 1.2787 Acc: 0.5200\n",
      "\n",
      "Epoch 9/50\n",
      "----------\n",
      "train Loss: 1.3025 Acc: 0.4125\n",
      "val Loss: 1.2907 Acc: 0.5200\n",
      "\n",
      "Epoch 10/50\n",
      "----------\n",
      "train Loss: 1.2499 Acc: 0.4125\n",
      "val Loss: 1.3132 Acc: 0.5200\n",
      "\n",
      "Epoch 11/50\n",
      "----------\n",
      "train Loss: 1.2029 Acc: 0.4125\n",
      "val Loss: 1.3516 Acc: 0.5600\n",
      "\n",
      "Epoch 12/50\n",
      "----------\n",
      "train Loss: 1.1837 Acc: 0.5125\n",
      "val Loss: 1.3290 Acc: 0.5600\n",
      "\n",
      "Epoch 13/50\n",
      "----------\n",
      "train Loss: 1.1464 Acc: 0.5000\n",
      "val Loss: 1.2529 Acc: 0.5200\n",
      "\n",
      "Epoch 14/50\n",
      "----------\n",
      "train Loss: 1.1010 Acc: 0.4125\n",
      "val Loss: 1.1720 Acc: 0.5200\n",
      "\n",
      "Epoch 15/50\n",
      "----------\n",
      "train Loss: 1.0701 Acc: 0.4750\n",
      "val Loss: 1.1415 Acc: 0.5600\n",
      "\n",
      "Epoch 16/50\n",
      "----------\n",
      "train Loss: 1.0306 Acc: 0.5375\n",
      "val Loss: 1.1344 Acc: 0.6400\n",
      "\n",
      "Epoch 17/50\n",
      "----------\n",
      "train Loss: 0.9808 Acc: 0.5625\n",
      "val Loss: 1.1515 Acc: 0.6800\n",
      "\n",
      "Epoch 18/50\n",
      "----------\n",
      "train Loss: 0.9361 Acc: 0.6500\n",
      "val Loss: 1.1307 Acc: 0.7200\n",
      "\n",
      "Epoch 19/50\n",
      "----------\n",
      "train Loss: 0.8807 Acc: 0.6625\n",
      "val Loss: 1.0786 Acc: 0.7200\n",
      "\n",
      "Epoch 20/50\n",
      "----------\n",
      "train Loss: 0.8306 Acc: 0.6375\n",
      "val Loss: 1.0315 Acc: 0.7600\n",
      "\n",
      "Epoch 21/50\n",
      "----------\n",
      "train Loss: 0.7757 Acc: 0.6625\n",
      "val Loss: 1.0009 Acc: 0.8000\n",
      "\n",
      "Epoch 22/50\n",
      "----------\n",
      "train Loss: 0.7170 Acc: 0.7250\n",
      "val Loss: 0.9898 Acc: 0.8000\n",
      "\n",
      "Epoch 23/50\n",
      "----------\n",
      "train Loss: 0.6727 Acc: 0.7750\n",
      "val Loss: 0.9814 Acc: 0.8000\n",
      "\n",
      "Epoch 24/50\n",
      "----------\n",
      "train Loss: 0.6258 Acc: 0.8375\n",
      "val Loss: 0.9350 Acc: 0.8000\n",
      "\n",
      "Epoch 25/50\n",
      "----------\n",
      "train Loss: 0.5677 Acc: 0.8250\n",
      "val Loss: 0.9132 Acc: 0.8000\n",
      "\n",
      "Epoch 26/50\n",
      "----------\n",
      "train Loss: 0.5412 Acc: 0.8250\n",
      "val Loss: 0.9088 Acc: 0.8000\n",
      "\n",
      "Epoch 27/50\n",
      "----------\n",
      "train Loss: 0.5009 Acc: 0.8625\n",
      "val Loss: 0.9160 Acc: 0.8800\n",
      "\n",
      "Epoch 28/50\n",
      "----------\n",
      "train Loss: 0.4550 Acc: 0.9125\n",
      "val Loss: 0.9105 Acc: 0.8400\n",
      "\n",
      "Epoch 29/50\n",
      "----------\n",
      "train Loss: 0.4310 Acc: 0.9125\n",
      "val Loss: 0.9164 Acc: 0.8800\n",
      "\n",
      "Epoch 30/50\n",
      "----------\n",
      "train Loss: 0.4050 Acc: 0.9125\n",
      "val Loss: 0.9297 Acc: 0.8400\n",
      "\n",
      "Epoch 31/50\n",
      "----------\n",
      "train Loss: 0.3777 Acc: 0.9125\n",
      "val Loss: 0.9304 Acc: 0.8800\n",
      "\n",
      "Epoch 32/50\n",
      "----------\n",
      "train Loss: 0.3610 Acc: 0.9125\n",
      "val Loss: 0.9451 Acc: 0.8800\n",
      "\n",
      "Epoch 33/50\n",
      "----------\n",
      "train Loss: 0.3442 Acc: 0.9125\n",
      "val Loss: 0.9692 Acc: 0.8400\n",
      "\n",
      "Epoch 34/50\n",
      "----------\n",
      "train Loss: 0.3332 Acc: 0.9000\n",
      "val Loss: 0.9911 Acc: 0.8400\n",
      "\n",
      "Epoch 35/50\n",
      "----------\n",
      "train Loss: 0.3210 Acc: 0.9000\n",
      "val Loss: 0.9831 Acc: 0.8800\n",
      "\n",
      "Epoch 36/50\n",
      "----------\n",
      "train Loss: 0.3218 Acc: 0.9125\n",
      "val Loss: 0.9954 Acc: 0.8800\n",
      "\n",
      "Epoch 37/50\n",
      "----------\n",
      "train Loss: 0.3109 Acc: 0.9125\n",
      "val Loss: 1.0269 Acc: 0.8400\n",
      "\n",
      "Epoch 38/50\n",
      "----------\n",
      "train Loss: 0.3326 Acc: 0.8875\n",
      "val Loss: 1.0278 Acc: 0.8400\n",
      "\n",
      "Epoch 39/50\n",
      "----------\n",
      "train Loss: 0.2863 Acc: 0.9125\n",
      "val Loss: 1.0417 Acc: 0.8800\n",
      "\n",
      "Epoch 40/50\n",
      "----------\n",
      "train Loss: 0.3191 Acc: 0.9250\n",
      "val Loss: 1.0406 Acc: 0.8400\n",
      "\n",
      "Epoch 41/50\n",
      "----------\n",
      "train Loss: 0.3011 Acc: 0.8875\n",
      "val Loss: 1.0766 Acc: 0.8400\n",
      "\n",
      "Epoch 42/50\n",
      "----------\n",
      "train Loss: 0.2676 Acc: 0.9000\n",
      "val Loss: 1.0534 Acc: 0.8800\n",
      "\n",
      "Epoch 43/50\n",
      "----------\n",
      "train Loss: 0.2845 Acc: 0.9250\n",
      "val Loss: 1.0658 Acc: 0.8800\n",
      "\n",
      "Epoch 44/50\n",
      "----------\n",
      "train Loss: 0.2948 Acc: 0.9250\n",
      "val Loss: 1.0763 Acc: 0.8400\n",
      "\n",
      "Epoch 45/50\n",
      "----------\n",
      "train Loss: 0.2772 Acc: 0.8625\n",
      "val Loss: 1.1033 Acc: 0.8400\n",
      "\n",
      "Epoch 46/50\n",
      "----------\n",
      "train Loss: 0.2651 Acc: 0.9000\n",
      "val Loss: 1.0948 Acc: 0.8400\n",
      "\n",
      "Epoch 47/50\n",
      "----------\n",
      "train Loss: 0.2598 Acc: 0.9250\n",
      "val Loss: 1.1041 Acc: 0.8400\n",
      "\n",
      "Epoch 48/50\n",
      "----------\n",
      "train Loss: 0.2826 Acc: 0.8875\n",
      "val Loss: 1.1192 Acc: 0.8400\n",
      "\n",
      "Epoch 49/50\n",
      "----------\n",
      "train Loss: 0.2726 Acc: 0.9125\n",
      "val Loss: 1.1072 Acc: 0.8800\n",
      "\n",
      "Epoch 50/50\n",
      "----------\n",
      "train Loss: 0.2733 Acc: 0.9250\n",
      "val Loss: 1.1238 Acc: 0.8400\n",
      "\n",
      "Training complete in 0m 4s\n",
      "Best val Acc: 0.880000\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model, val_acc_history = train_model(model, dataloaders_dict, criterion, num_epochs, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8DGoSD97zS4"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYoOfr9A7zS4"
   },
   "source": [
    "# <br>__4. Testing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:34.974525Z",
     "iopub.status.busy": "2022-01-10T11:57:34.974117Z",
     "iopub.status.idle": "2022-01-10T11:57:34.981675Z",
     "shell.execute_reply": "2022-01-10T11:57:34.980937Z",
     "shell.execute_reply.started": "2022-01-10T11:57:34.974486Z"
    },
    "id": "rR0_F4Ey7zS4"
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()   # 모델을 validation mode로 설정\n",
    "    \n",
    "    # test_loader에 대하여 검증 진행 (gradient update 방지)\n",
    "    with torch.no_grad():\n",
    "        corrects = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "            # forward\n",
    "            # input을 model에 넣어 output을 도출\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # output 중 최댓값의 위치에 해당하는 class로 예측을 수행\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # batch별 정답 개수를 축적함\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # accuracy를 도출함\n",
    "    test_acc = corrects.double() / total\n",
    "    print('Testing Acc: {:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-01-10T11:57:34.983656Z",
     "iopub.status.busy": "2022-01-10T11:57:34.983342Z",
     "iopub.status.idle": "2022-01-10T11:57:35.001756Z",
     "shell.execute_reply": "2022-01-10T11:57:35.001094Z",
     "shell.execute_reply.started": "2022-01-10T11:57:34.983614Z"
    },
    "id": "qrj5NHBc7zS5",
    "outputId": "ab209709-12f3-4e7d-fb6d-215d710a7c95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Acc: 0.8222\n"
     ]
    }
   ],
   "source": [
    "# 모델 검증 (Acc: 0.8222)\n",
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2j3jF3A7zS5"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "02_CNN_for_Time_Series_Data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
